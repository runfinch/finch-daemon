name: samcli-sequential

on:
  push:
    branches:
      - main
    paths:
      - '**.go'
      - 'go.mod'
      - 'go.sum'
      - '.github/workflows/samcli_sequential.yaml'
      - 'Makefile*'
      - 'cmd/**'
      - 'pkg/**'
      - 'internal/**'
      - 'api/**'
  pull_request:
    branches:
      - main
    paths:
      - '**.go'
      - 'go.mod'
      - 'go.sum'
      - '.github/workflows/samcli_sequential.yaml'
      - 'Makefile*'
      - 'cmd/**'
      - 'pkg/**'
      - 'internal/**'
      - 'api/**'
  workflow_dispatch:

env:
  GO_VERSION: '1.23.8'
  CONTAINERD_VERSION: "1.7.27"

permissions:
  id-token: write
  contents: read

jobs:
  samcli-tests:
    runs-on: ubuntu-latest
    timeout-minutes: 360  # 6 hours for all tests
    env:
      AWS_DEFAULT_REGION: ${{ secrets.REGION }}
      DOCKER_HOST: unix:///run/finch.sock
      BY_CANARY: true  # Full AWS access for all tests
      SAM_CLI_DEV: 1 
    steps:
      - name: Set up Go
        uses: actions/setup-go@d35c59abb061a4a6fb18e82ac0862c26744d6ab5 # v5.5.0
        with:
          go-version: ${{ env.GO_VERSION }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11.12'

      - name: Checkout finch-daemon repo
        uses: actions/checkout@692973e3d937129bcbf40652eb9f2f61becf3332 # v4.1.7

      - name: Stop pre-existing services
        run: |
          sudo systemctl stop docker
          sudo systemctl stop containerd

      - name: Remove default podman network config
        run: |
          sudo rm -f /etc/cni/net.d/87-podman-bridge.conflist

      - name: Clean up Daemon socket
        run: |
          sudo rm -f /run/finch.sock
          sudo rm -f /run/finch.pid
          sudo rm -f /run/finch-credential.sock

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@b47578312673ae6fa5b5096b330d9fbac3d116df # v4.2.1
        with:
          role-to-assume: ${{ secrets.ROLE }}
          role-session-name: samcli-sequential-tests
          aws-region: ${{ secrets.REGION }}
          role-duration-seconds: 14400

      - name: Verify AWS credentials
        run: |
          aws sts get-caller-identity --query 'Account' --output text >/dev/null
          echo "AWS credentials configured successfully"

      - name: Install and validate finch-daemon dependencies
        run: |
          ./setup-test-env.sh
          sleep 10
          sudo chmod 666 /run/buildkit/buildkitd.sock

      - name: Build and start finch-daemon
        run: |
          make build
          sudo cp bin/docker-credential-finch /usr/bin
          sudo bin/finch-daemon --debug --socket-owner $UID 2>&1 | tee finch-daemon.log &  
          FINCH_PID=$!        
          sleep 10
          curl --unix-socket /run/finch.sock http://localhost/_ping
          echo "Finch-daemon started with PID: $FINCH_PID"
          
          # Generate ECR credentials using AWS credentials from previous step
          echo "Generating ECR credentials..."
          ECR_TOKEN=$(aws ecr get-login-password --region $AWS_DEFAULT_REGION)
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          
          # Create finch config directory (matching regular finch location)
          mkdir -p /home/runner/.finch
          
          echo "AWS_DEFAULT_REGION: '$AWS_DEFAULT_REGION'"
          # Create Docker config with ONLY private ECR credentials (public ECR doesn't need auth)
          cat > /home/runner/.finch/config.json << EOF
          {
            "auths": {
              "docker.io": {},
              "public.ecr.aws": {},
              "$AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com": {
                "auth": "$(echo "AWS:$ECR_TOKEN" | base64 -w 0)"
              }
            }
          }
          EOF
          
          # Set Docker to use finch config location (matching regular finch)
          echo "DOCKER_CONFIG=/home/runner/.finch" >> $GITHUB_ENV
          
          # Verify config was created
          echo "Docker config created (private ECR only):"
          cat /home/runner/.finch/config.json
          echo "DOCKER_CONFIG set to: /home/runner/.finch"

      - name: Debug BuildKit Manual Test
        run: |
          echo "=== BUILDKIT VERSION & INFO ==="
          sudo /usr/local/bin/buildctl --version
          echo ""

          echo "=== BUILDKIT WORKERS ==="
          sudo /usr/local/bin/buildctl --addr=unix:///run/buildkit/buildkitd.sock debug workers
          echo ""

          echo "=== BUILDKIT DEBUG INFO ==="
          sudo /usr/local/bin/buildctl --addr=unix:///run/buildkit/buildkitd.sock debug info
          echo ""

          echo "=== MANUAL BUILDKIT TEST ==="
          # Create simple test context
          mkdir -p /tmp/test-build
          echo "FROM alpine:latest" > /tmp/test-build/Dockerfile
          echo "RUN echo hello world" >> /tmp/test-build/Dockerfile

          echo "Testing BuildKit docker output to file..."
          sudo /usr/local/bin/buildctl --addr=unix:///run/buildkit/buildkitd.sock build \
            --progress=plain \
            --frontend=dockerfile.v0 \
            --local=context=/tmp/test-build \
            --local=dockerfile=/tmp/test-build \
            --opt=filename=Dockerfile \
            --output=type=docker,name=test:latest > /tmp/buildkit-output.tar 2>&1

          echo "BuildKit output file size: $(wc -c < /tmp/buildkit-output.tar)"
          echo "BuildKit output first 200 bytes (hex):"
          head -c 200 /tmp/buildkit-output.tar | hexdump -C || echo "No output to display"

          echo "BuildKit output first 5 lines (text):"
          head -5 /tmp/buildkit-output.tar || echo "No text output"

      - name: Clean up SAM managed stack (robust)
        run: |
          STACK_NAME="aws-sam-cli-managed-default"
          echo "=== Cleaning up SAM managed stack ==="
          
          # Check if stack exists and get its status
          if aws cloudformation describe-stacks --stack-name "$STACK_NAME" --region $AWS_DEFAULT_REGION >/dev/null 2>&1; then
            STACK_STATUS=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" --region $AWS_DEFAULT_REGION --query 'Stacks[0].StackStatus' --output text)
            echo "Found existing stack with status: $STACK_STATUS"
            
            # Get the S3 bucket name from stack outputs
            BUCKET_NAME=$(aws cloudformation describe-stacks --stack-name "$STACK_NAME" --region $AWS_DEFAULT_REGION --query 'Stacks[0].Outputs[?OutputKey==`SourceBucket`].OutputValue' --output text 2>/dev/null || echo "")
            
            if [ -n "$BUCKET_NAME" ]; then
              echo "Found S3 bucket: $BUCKET_NAME"
              echo "Emptying S3 bucket before stack deletion..."
              
              # Delete all object versions and delete markers
              aws s3api list-object-versions --bucket "$BUCKET_NAME" --query 'Versions[].{Key:Key,VersionId:VersionId}' --output text | while read key version; do
                if [ -n "$key" ] && [ -n "$version" ]; then
                  aws s3api delete-object --bucket "$BUCKET_NAME" --key "$key" --version-id "$version" || true
                fi
              done
              
              # Delete any delete markers
              aws s3api list-object-versions --bucket "$BUCKET_NAME" --query 'DeleteMarkers[].{Key:Key,VersionId:VersionId}' --output text | while read key version; do
                if [ -n "$key" ] && [ -n "$version" ]; then
                  aws s3api delete-object --bucket "$BUCKET_NAME" --key "$key" --version-id "$version" || true
                fi
              done
              
              echo "S3 bucket emptied successfully"
            else
              echo "No S3 bucket found in stack outputs"
            fi
            
            # Force continue rollback only for specific failed states
            if [[ "$STACK_STATUS" == "UPDATE_ROLLBACK_FAILED" ]]; then
              echo "Stack is in UPDATE_ROLLBACK_FAILED state, attempting to continue rollback..."
              aws cloudformation continue-update-rollback --stack-name "$STACK_NAME" --region $AWS_DEFAULT_REGION || true
              sleep 30
            elif [[ "$STACK_STATUS" == *"FAILED"* ]]; then
              echo "Stack is in failed state ($STACK_STATUS), will attempt direct deletion..."
            fi
            
            # Delete stack
            echo "Deleting existing SAM managed stack..."
            aws cloudformation delete-stack --stack-name "$STACK_NAME" --region $AWS_DEFAULT_REGION || true
            
            # Wait for deletion with timeout
            echo "Waiting for stack deletion to complete (max 10 minutes)..."
            timeout 600 aws cloudformation wait stack-delete-complete --stack-name "$STACK_NAME" --region $AWS_DEFAULT_REGION || echo "Stack deletion timed out or failed, continuing anyway..."
            echo "✅ Stack cleanup completed"
          else
            echo "No existing SAM managed stack found - starting fresh"
          fi

          echo "=== Additional resource cleanup ==="
          
          # Clean up orphaned Lambda layers (created by tests)
          echo "Cleaning up test Lambda layers..."
          aws lambda list-layers --region $AWS_DEFAULT_REGION --query 'Layers[].LayerName' --output text | tr '\t' '\n' | while read layer_name; do
            if [[ "$layer_name" =~ ^(sam-cli-|test-|layer-|TestLayer) ]]; then
              echo "Found test layer: $layer_name"
              # Get all versions of this layer
              aws lambda list-layer-versions --layer-name "$layer_name" --region $AWS_DEFAULT_REGION --query 'LayerVersions[].Version' --output text | tr '\t' '\n' | while read version; do
                echo "Deleting layer version: $layer_name:$version"
                aws lambda delete-layer-version --layer-name "$layer_name" --version-number "$version" --region $AWS_DEFAULT_REGION || true
              done
            fi
          done || true

          # Clean up test CloudFormation stacks
          echo "Cleaning up test CloudFormation stacks..."
          aws cloudformation list-stacks --region $AWS_DEFAULT_REGION --query 'StackSummaries[?starts_with(StackName, `sam-`) && StackStatus != `DELETE_COMPLETE`].StackName' --output text | tr '\t' '\n' | while read stack_name; do
            if [ -n "$stack_name" ] && [ "$stack_name" != "$STACK_NAME" ]; then
              echo "Found test stack: $stack_name"
              aws cloudformation delete-stack --stack-name "$stack_name" --region $AWS_DEFAULT_REGION || true
            fi
          done || true

          # Clean up test S3 buckets
          echo "Cleaning up test S3 buckets..."
          aws s3api list-buckets --query 'Buckets[?starts_with(Name, `sam-cli-`) || starts_with(Name, `aws-sam-cli-`)].Name' --output text | tr '\t' '\n' | while read bucket_name; do
            if [ -n "$bucket_name" ]; then
              echo "Found test bucket: $bucket_name"
              # Empty bucket first
              aws s3 rm s3://$bucket_name --recursive || true
              # Delete bucket
              aws s3api delete-bucket --bucket "$bucket_name" --region $AWS_DEFAULT_REGION || true
            fi
          done || true

          # Clean up orphaned Lambda functions (not in stacks)
          echo "Cleaning up test Lambda functions..."
          aws lambda list-functions --region $AWS_DEFAULT_REGION --query 'Functions[?starts_with(FunctionName, `sam-cli-`) || starts_with(FunctionName, `test-`)].FunctionName' --output text | tr '\t' '\n' | while read function_name; do
            if [ -n "$function_name" ]; then
              echo "Found test function: $function_name"
              aws lambda delete-function --function-name "$function_name" --region $AWS_DEFAULT_REGION || true
            fi
          done || true

          echo "✅ Additional cleanup completed"

      - name: Set up SAM CLI from source
        run: |
          git clone https://github.com/aws/aws-sam-cli.git
          cd aws-sam-cli
          git checkout $(git describe --tags `git rev-list --tags --max-count=1`)  # Latest tag
          git submodule update --init --recursive
          python -m pip install --upgrade pip
          make init
          samdev --version

      # - name: Run unit tests
      #   working-directory: aws-sam-cli
      #   run: |
      #     echo "=== UNIT TESTS - Started at $(date) ==="
          
      #     # Fix common issues from test guide
      #     ulimit -n 8192  # Fix "too many open files" 
          
      #     # Clean up potentially problematic Docker config entries
      #     if [ -f ~/.docker/config.json ]; then
      #       if command -v jq >/dev/null 2>&1; then
      #         jq 'del(.credsStore)' ~/.docker/config.json > ~/.docker/config.json.tmp && mv ~/.docker/config.json.tmp ~/.docker/config.json
      #       else
      #         sed -i '/"credsStore"/d' ~/.docker/config.json
      #       fi
      #     fi
          
      #     make test | tee unit_test_output.txt
          
      #     # Check coverage (should be ~94%)
      #     COVERAGE=$(grep -o "[0-9]\+%" unit_test_output.txt | head -1 | tr -d '%')
      #     if [ -z "$COVERAGE" ] || [ "$COVERAGE" -lt 90 ]; then
      #       echo "❌ Coverage below threshold! Got: $COVERAGE%, Expected: ~94%"
      #       exit 1
      #     else
      #       echo "✅ Unit tests passed with $COVERAGE% coverage"
      #     fi
      #   continue-on-error: true

      - name: Verbose Testing
        working-directory: aws-sam-cli
        run: |
          SAM_CLI_DEV=1 python -m pytest tests/integration/local/invoke/test_integration_cli_images.py::TestSamPython36HelloWorldIntegrationImages::test_invoke_with_env_vars -v -s --tb=long
        continue-on-error: false

      - name: Run invoke tests
        working-directory: aws-sam-cli
        run: |
          echo "=== INVOKE TESTS - Started at $(date) ==="
          SAM_CLI_DEV=1 timeout 90m python -m pytest tests/integration/local/invoke -k 'not Terraform' -v --tb=short > invoke_output.txt 2>&1 || true
          
          echo "=== INVOKE TEST OUTPUT ==="
          cat invoke_output.txt
          echo "=== END INVOKE TEST OUTPUT ==="
          
          # Expected failures from test guide (12 total from different test classes)
          cat > expected_invoke_failures.txt << 'EOF'
          test_invoke_with_error_during_image_build
          test_invoke_with_timeout_set_0_TimeoutFunction
          test_invoke_with_timeout_set_1_TimeoutFunctionWithParameter
          test_invoke_with_timeout_set_2_TimeoutFunctionWithStringParameter
          test_building_new_rapid_image_removes_old_rapid_images
          test_invoke_returns_expected_results_from_git_function
          test_invoke_returns_expected_results_from_git_function_with_parameters
          EOF
          
          # Note: Guide shows 12 failures but some test names repeat across different test classes
          # The sed extraction will capture all instances regardless of test class
          
          # Extract actual failures
          grep "FAILED" invoke_output.txt | sed 's/.*::\(test_[a-zA-Z0-9_]*\).*/\1/' > actual_invoke_failures.txt || true
          
          # Find unexpected failures
          UNEXPECTED=$(grep -v -f expected_invoke_failures.txt actual_invoke_failures.txt 2>/dev/null || true)
          
          if [ -n "$UNEXPECTED" ]; then
            echo "❌ Unexpected failures found:"
            echo "$UNEXPECTED"
            exit 1
          else
            echo "✅ All failures were expected (guide shows 12 known issues across test classes)"
          fi
        continue-on-error: true

      - name: Run start-lambda tests
        working-directory: aws-sam-cli
        run: |
          echo "=== START-LAMBDA TESTS - Started at $(date) ==="
          SAM_CLI_DEV=1 timeout 45m python -m pytest tests/integration/local/start_lambda -k 'not Terraform' -v --tb=short > start_lambda_output.txt 2>&1 || true
          
          echo "=== START-LAMBDA TEST OUTPUT ==="
          cat start_lambda_output.txt
          echo "=== END START-LAMBDA TEST OUTPUT ==="
          
          # Should pass completely per test guide
          if grep -q "FAILED" start_lambda_output.txt; then
            echo "❌ Start-lambda tests failed (should pass completely)"
            grep "FAILED" start_lambda_output.txt
            exit 1
          else
            echo "✅ All start-lambda tests passed as expected"
          fi
        continue-on-error: true

      - name: Run start-api tests
        working-directory: aws-sam-cli
        run: |
          echo "=== START-API TESTS - Started at $(date) ==="
          ulimit -n 8192
          SAM_CLI_DEV=1 timeout 90m python -m pytest tests/integration/local/start_api -k 'not Terraform' -v --tb=short > start_api_output.txt 2>&1 || true

          echo "=== START-API TEST OUTPUT ==="
          cat start_api_output.txt
          echo "=== END START-API TEST OUTPUT ==="
          
          # Should pass completely per test guide
          if grep -q "FAILED" start_api_output.txt; then
            echo "❌ Start-api tests failed (should pass completely)"
            grep "FAILED" start_api_output.txt
            exit 1
          else
            echo "✅ All start-api tests passed as expected"
          fi
        continue-on-error: true

      - name: Run sync tests  
        working-directory: aws-sam-cli
        run: |
          echo "=== SYNC TESTS - Started at $(date) ==="
          AWS_DEFAULT_REGION=$AWS_DEFAULT_REGION SAM_CLI_DEV=1 timeout 30m python -m pytest tests/integration/sync -k 'image' -v --tb=short > sync_output.txt 2>&1 || true
          
          echo "=== SYNC TEST OUTPUT ==="
          cat sync_output.txt
          echo "=== END SYNC TEST OUTPUT ==="
          
          # Should pass completely per test guide
          if grep -q "FAILED" sync_output.txt; then
            echo "❌ Sync tests failed (should pass completely)"
            grep "FAILED" sync_output.txt
            exit 1
          else
            echo "✅ All sync tests passed as expected"
          fi
        continue-on-error: true

      - name: Run package tests
        working-directory: aws-sam-cli  
        run: |
          echo "=== PACKAGE TESTS - Started at $(date) ==="
          AWS_DEFAULT_REGION=$AWS_DEFAULT_REGION SAM_CLI_DEV=1 SAM_CLI_TELEMETRY=0 timeout 15m python -m pytest tests/integration/package/test_package_command_image.py -v --tb=short > package_output.txt 2>&1 || true
          
          echo "=== PACKAGE TEST OUTPUT ==="
          cat package_output.txt
          echo "=== END PACKAGE TEST OUTPUT ==="
          
          # Expected failures from test guide
          cat > expected_package_failures.txt << 'EOF'
          test_package_with_deep_nested_template_image
          test_package_template_with_image_repositories_nested_stack
          test_package_with_loadable_image_archive_0_template_image_load_yaml
          EOF
          
          # Extract actual failures
          grep "FAILED" package_output.txt | sed 's/.*::\(test_[a-zA-Z0-9_]*\).*/\1/' > actual_package_failures.txt || true
          
          # Also check for nested stack failures (pattern match)
          grep "FAILED.*test_package_template_with_image_repositories_nested_stack" package_output.txt >> actual_package_failures.txt || true
          
          # Find unexpected failures (exclude nested stack pattern)
          UNEXPECTED=$(grep -v -f expected_package_failures.txt actual_package_failures.txt | grep -v "test_package_template_with_image_repositories_nested_stack" || true)
          
          if [ -n "$UNEXPECTED" ]; then
            echo "❌ Unexpected failures found:"
            echo "$UNEXPECTED"
            exit 1
          else
            echo "✅ All failures were expected (3 known issues)"
          fi
        continue-on-error: true

      - name: Run deploy tests
        working-directory: aws-sam-cli
        run: |
          echo "=== DEPLOY TESTS - Started at $(date) ==="
          AWS_DEFAULT_REGION=$AWS_DEFAULT_REGION SAM_CLI_DEV=1 timeout 45m python -m pytest tests/integration/deploy -k 'image' -v --tb=short > deploy_output.txt 2>&1 || true
          
          echo "=== DEPLOY TEST OUTPUT ==="
          cat deploy_output.txt
          echo "=== END DEPLOY TEST OUTPUT ==="
          
          # Check for arbitrary passes (PASSED with errors in preceding lines)
          ARBITRARY_PASSES=""
          if grep -q "PASSED" deploy_output.txt; then
            # Get line numbers of PASSED tests
            grep -n "PASSED" deploy_output.txt | while read line; do
              LINE_NUM=$(echo "$line" | cut -d: -f1)
              TEST_NAME=$(echo "$line" | grep -o "test_[a-zA-Z0-9_]*")
              
              # Check 10 lines before for errors
              START_LINE=$((LINE_NUM - 10))
              if [ $START_LINE -lt 1 ]; then START_LINE=1; fi
              
              # Look for error indicators in preceding lines
              if sed -n "${START_LINE},${LINE_NUM}p" deploy_output.txt | grep -qi "error\|exception\|fail\|traceback"; then
                echo "⚠️  Arbitrary pass detected: $TEST_NAME (errors found before PASSED)"
                ARBITRARY_PASSES="$ARBITRARY_PASSES $TEST_NAME"
              fi
            done
          fi
          
          PASSED_COUNT=$(grep -c "PASSED" deploy_output.txt || echo "0")
          FAILED_COUNT=$(grep -c "FAILED" deploy_output.txt || echo "0")
          
          echo "Deploy results: $PASSED_COUNT passed, $FAILED_COUNT failed"
          
          # Most should fail due to multi-arch limitation
          if [ "$FAILED_COUNT" -eq 0 ]; then
            echo "❌ No deploy tests failed (expected most to fail due to multi-arch)"
            exit 1
          elif [ -n "$ARBITRARY_PASSES" ]; then
            echo "✅ Deploy tests mostly failed as expected, with some arbitrary passes (errors present but test passed)"
          else
            echo "✅ Deploy tests behaved as expected (multi-arch limitation)"
          fi
        continue-on-error: true

      # - name: Run build tests
      #   working-directory: aws-sam-cli
      #   run: |
      #     echo "=== BUILD TESTS - Started at $(date) ==="
      #     SAM_CLI_DEV=1 timeout 60m python -m pytest tests/integration/buildcmd -k '(container or image) and not sar and not terraform' -v --tb=short > build_output.txt 2>&1 || true
          
      #     echo "=== BUILD TEST OUTPUT ==="
      #     cat build_output.txt
      #     echo "=== END BUILD TEST OUTPUT ==="
          
      #     # Expected failures from test guide (nerdctl ancestor filter limitation)
      #     cat > expected_build_failures.txt << 'EOF'
      #     test_with_invalid_dockerfile_definition
      #     test_with_invalid_dockerfile_location
      #     test_load_success
      #     test_building_ruby_3_2_1_use_container
      #     test_with_makefile_builder_specified_python_runtime_1_use_container
      #     test_with_native_builder_specified_python_runtime_1_use_container
      #     test_inline_not_built_1_use_container
      #     test_json_env_vars_passed_0_use_container
      #     test_json_env_vars_passed_1_use_container
      #     test_inline_env_vars_passed_0_use_container
      #     test_inline_env_vars_passed_1_use_container
      #     test_custom_build_image_succeeds_0_use_container
      #     test_custom_build_image_succeeds_1_use_container
      #     test_building_ruby_in_container_with_specified_architecture_0_ruby3_2
      #     test_building_java_in_container_with_arm64_architecture_00_java8_al2
      #     test_building_java_in_container_with_arm64_architecture_03_java8_al2
      #     test_building_java_in_container_with_arm64_architecture_04_java11
      #     test_building_java_in_container_with_arm64_architecture_07_java11
      #     test_building_java_in_container_with_arm64_architecture_08_java17
      #     test_building_java_in_container_with_arm64_architecture_11_java17
      #     test_building_java_in_container_with_arm64_architecture_al2023_0_java21
      #     test_building_java_in_container_with_arm64_architecture_al2023_1_java21
      #     test_building_java_in_container_with_arm64_architecture_al2023_2_java21
      #     test_building_java_in_container_with_arm64_architecture_al2023_3_java21
      #     test_building_java_in_container_00_java8_al2
      #     EOF
          
      #     # Extract actual failures
      #     grep "FAILED" build_output.txt | sed 's/.*::\(test_[a-zA-Z0-9_]*\).*/\1/' > actual_build_failures.txt || true
          
      #     # Find unexpected failures
      #     UNEXPECTED=$(grep -v -f expected_build_failures.txt actual_build_failures.txt 2>/dev/null || true)
          
      #     if [ -n "$UNEXPECTED" ]; then
      #       echo "❌ Unexpected failures found:"
      #       echo "$UNEXPECTED"
      #       exit 1
      #     else
      #       echo "✅ All failures were expected (nerdctl ancestor filter limitation)"
      #     fi
      #   continue-on-error: true

      - name: Show finch-daemon logs
        if: always()
        run: |
          echo "=== FINCH-DAEMON OUTPUT ==="
          cat finch-daemon.log || echo "No log file found"

      - name: Final cleanup
        if: always()
        run: |
          echo "=== Final cleanup ==="
          # Clean up any remaining SAM managed stack
          STACK_NAME="aws-sam-cli-managed-default"
          if aws cloudformation describe-stacks --stack-name "$STACK_NAME" --region $AWS_DEFAULT_REGION >/dev/null 2>&1; then
            echo "Cleaning up final SAM managed stack..."
            aws cloudformation delete-stack --stack-name "$STACK_NAME" --region $AWS_DEFAULT_REGION || true
          fi
          echo "Cleanup completed"
